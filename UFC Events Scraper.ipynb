{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ee4afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e7eca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create csv file to add scraped data to\n",
    "def create_csv_file():\n",
    "    #Checks if file already exists - if not, creates new file with column headers\n",
    "    if 'ufc_event_data.csv' not in os.listdir():\n",
    "        with open('ufc_event_data.csv','w', newline='',encoding='UTF8') as ufc_event_data:\n",
    "            writer = csv.writer(ufc_event_data)\n",
    "            writer.writerow(['event_name',\n",
    "                             'event_date',\n",
    "                             'event_city',\n",
    "                             'event_state',\n",
    "                             'event_country',\n",
    "                             'event_url'])\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c766fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape url of each UFC event from ufcstats.com\n",
    "def get_event_urls():\n",
    "    main_url = requests.get('http://ufcstats.com/statistics/events/completed?page=all')\n",
    "    main_soup = bs4.BeautifulSoup(main_url.text, 'lxml')\n",
    "    \n",
    "    #Adds href to list if href (1) contains a link, (2) contains keyword 'event-details', and (3) has not been scraped already\n",
    "    all_event_urls = [item.get('href') for item in  main_soup.find_all('a') \n",
    "                      if type(item.get('href')) == str \n",
    "                      and 'event-details' in item.get('href')]\n",
    "    \n",
    "    return all_event_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9eee38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ensure each url is only scraped once when script is run multiple times\n",
    "def prevent_duplicates(event_urls):\n",
    "    if 'ufc_event_data.csv' in os.listdir():\n",
    "        with open('ufc_event_data.csv','r') as csv_file:\n",
    "            reader = csv.DictReader(csv_file)\n",
    "            scraped_event_urls = [row['event_url'] for row in reader]\n",
    "            for url in scraped_event_urls:\n",
    "                if url in event_urls:\n",
    "                    event_urls.remove(url)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "903e80f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to scrape details of each UFC event and add to append to file\n",
    "def get_event_data(event_urls):\n",
    "\n",
    "    prevent_duplicates(event_urls)\n",
    "    \n",
    "    with open('ufc_event_data.csv','a+') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "    \n",
    "        for event in event_urls:\n",
    "            event_request = requests.get(event)\n",
    "            event_soup = bs4.BeautifulSoup(event_request.text,'lxml')\n",
    "\n",
    "            event_name = event_soup.select('h2')[0].text\n",
    "            event_date = event_soup.select('li')[3].text.split(':')[-1]\n",
    "            event_full_location = event_soup.select('li')[4].text.split(':')[1].strip().split(',')\n",
    "            event_city = event_soup.select('li')[4].text.split(':')[1].strip().split(',')[0]\n",
    "            event_country = event_soup.select('li')[4].text.split(':')[1].strip().split(',')[-1]\n",
    "            event_url = event\n",
    "\n",
    "            #Check if event address includes state and add to event_state if True\n",
    "            if len(event_full_location)>2:\n",
    "                   event_state = event_soup.select('li')[4].text.split(':')[1].strip().split(',')[1]\n",
    "            else:\n",
    "                   event_state = 'NULL'\n",
    "\n",
    "\n",
    "            writer.writerow([event_name.strip(), \n",
    "                             event_date.strip(), \n",
    "                             event_city.strip(), \n",
    "                             event_state.strip(), \n",
    "                             event_country.strip(), \n",
    "                             event_url.strip()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "666dd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db667d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_urls = get_event_urls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "prevent_duplicates(event_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc034cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_event_data(event_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd72a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c1d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30678f52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
